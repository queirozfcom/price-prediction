{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "although the problem is probably **best seen as a regression problem**, I've chosen to use neural networks for this approach because \n",
    "\n",
    "**a)** they are nonlinear models and \n",
    "\n",
    "**b)** even though we are doing classification, neural nets (when using softmax output function) output a probability for *each* output so we will get probabilities for each of the possible outputs (quantity buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# helper functions\n",
    "sys.path.insert(0, \"../src/lib\")\n",
    "\n",
    "import dataset as dataset_funcs\n",
    "import cleaning as cleaning_funcs\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROD_ID</th>\n",
       "      <th>DATE_ORDER</th>\n",
       "      <th>QTY_ORDER</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>UNIT_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51347</th>\n",
       "      <td>P7</td>\n",
       "      <td>2015-06-10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>799.000</td>\n",
       "      <td>799.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277848</th>\n",
       "      <td>P8</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>1.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>379.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66703</th>\n",
       "      <td>P7</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>1.000</td>\n",
       "      <td>749.000</td>\n",
       "      <td>749.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286360</th>\n",
       "      <td>P8</td>\n",
       "      <td>2015-10-13</td>\n",
       "      <td>1.000</td>\n",
       "      <td>379.000</td>\n",
       "      <td>379.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154504</th>\n",
       "      <td>P7</td>\n",
       "      <td>2015-02-06</td>\n",
       "      <td>1.000</td>\n",
       "      <td>849.000</td>\n",
       "      <td>849.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PROD_ID DATE_ORDER  QTY_ORDER  REVENUE  UNIT_PRICE\n",
       "51347       P7 2015-06-10      1.000  799.000     799.000\n",
       "277848      P8 2015-08-21      1.000  379.000     379.000\n",
       "66703       P7 2015-07-20      1.000  749.000     749.000\n",
       "286360      P8 2015-10-13      1.000  379.000     379.000\n",
       "154504      P7 2015-02-06      1.000  849.000     849.000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df = pd.read_csv('../data/raw/sales.csv')\n",
    "sales_df.DATE_ORDER = sales_df.DATE_ORDER.astype(\"datetime64\")\n",
    "sales_df[\"UNIT_PRICE\"] = sales_df[\"REVENUE\"] / sales_df[\"QTY_ORDER\"]\n",
    "sales_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "as we mentioned on the **EXPLORATORY DATA ANALYSIS**, we will remove some bad data from our dataset to avoid propagating these errors to the model (using helper functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351090, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df = cleaning_funcs.clean_sales_dataframe(sales_df)\n",
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "let's split the data into each product (because each product may have different dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "group_ids = ['P1','P2','P3','P4','P5','P6','P7','P8','P9']\n",
    "grouped = sales_df.groupby([sales_df.PROD_ID])\n",
    "(p1,p2,p3,p4,p5,p6,p7,p8,p9) = [grouped.get_group(prod_id) for prod_id in group_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "let's use P7 in the first run because it's the product the with the most available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p7 = p7.sort_values(['DATE_ORDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now just select the columns we will use in this very simple model\n",
    "p7 = p7[[\"UNIT_PRICE\",\"QTY_ORDER\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> I will perform a transformation to make this dataset more amenable to classification.\n",
    "\n",
    "Although (as I said before) classification may not be the best way to approach this problem, we can make it a little bit better if we reduce the cardinality of the target and we make it more \"discrete\". In other words, I will reduce the space of possible targets from a continuous range to a discrete set of choices.\n",
    "\n",
    "Since values larger than 10.0 for the QTY_ORDER are exceedingly rare, let's consider all values larger than or equal to 10 as just 10. \n",
    "\n",
    "This change will cause the dataset to have just 9 possible choices for the target, thereby making it more amenable to classification (rather than regression) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p7[\"QTY_ORDER\"] = p7[\"QTY_ORDER\"].apply(lambda qty: 10.0 if qty >= 10.0 else qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X,y = dataset_funcs.make_Xy_simple(p7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((195938, 1), (195938,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For this approach I will use a simple neural network with softmax output function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "neural networks work better with normalized, standardized data, so we need to rescale data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()  \n",
    "# if we were running a production system, we would obviously just fit on the training data\n",
    "sc.fit(X)  \n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tanh gives us more smoothness than the default rectified unit\n",
    "mlp = MLPClassifier(activation='tanh')\n",
    "mlp.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since our target column (y) has multiple (discrete) values (categories), sklearn's implementation of neural nets will automatically infer we want to get predictions for all categories, and will make method `predict_proba` available for us.\n",
    "\n",
    "`predict_proba` takes an input as parameter and outputs the predicted probability of *each* category. So if we call `classifier.predict_proba(1200)`, we will get as result an array of 9 elements, the first element being the probability that QTY_ORDER is 1, the second being the probability that QTY_ORDER is 2, and so on.\n",
    "\n",
    "> Note that, since the outputs of `predict_proba` are probabilities, they must always sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.99470467e-01,   3.21877380e-02,   5.92790407e-03,\n",
       "          5.47249721e-03,   1.79870732e-03,   2.21117699e-06,\n",
       "          1.76275238e-02,   3.65303541e-02,   9.82597760e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict_proba(np.array([1200]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "comments: this solution is a little bit unstable (may yield different results every time it's run) because of the inherent stochasticity of methods such as SGD (stochastic gradient descent) used in training neural nets (when trained using mini-batch learning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
