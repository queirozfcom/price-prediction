{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1ee4857e2dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../src/lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataset_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcleaning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcleaning_funcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/teste-b2w/src/lib/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "# helper functions\n",
    "sys.path.insert(0, \"../src/lib\")\n",
    "\n",
    "import dataset as dataset_funcs\n",
    "import cleaning as cleaning_funcs\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Approach and feature extraction**\n",
    "\n",
    "The first approach is very naÃ¯ve, because sometimes really simple models give good results and are easy and cheap to build (also, you can give some kind of early information to decision-makers while you are still working on a more sophisticated model).\n",
    "\n",
    "Using **just sales data**, transform the dataset into a new dataset where each pair (X_i, y_i) is the following:\n",
    "\n",
    "X_i = 3 (or 4, or 5) prices for 3 (or 4, or 5) sequential days (for a single product)\n",
    "y_i = price for the next day\n",
    "\n",
    "So we learn a very simple model that estimates the next price (for a single product)\n",
    "\n",
    "> note that we have two subapproaches: in the first one we train on each product type separately and in the second one we train on all products togethers. This is meant to investigate whether we can increase performance when using data from all products.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- the model is stationary, i.e. the target function does not change over time, in other words, the way the previous prices affect the next one does not change depending upon what month of the year we're in.\n",
    "\n",
    "**Shortcomings**\n",
    "\n",
    "- we do not use data from competitors\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "- squared error, since we're dealing with continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('../data/raw/sales.csv')\n",
    "sales_df.DATE_ORDER = sales_df.DATE_ORDER.astype(\"datetime64\")\n",
    "sales_df[\"UNIT_PRICE\"] = sales_df[\"REVENUE\"] / sales_df[\"QTY_ORDER\"]\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "right now the index is just numbers, but pandas allows us to inform that each index refers to a special Period in time (in this case, a day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> note that using a PeriodIndex is different from just using a DatetimeIndex because then pandas would just think you want to index the data by a particular point in time, rather than by the whole day, as is the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# periods = list(map(lambda dt: pd.Period(dt),sales_df[\"DATE_ORDER\"]))\n",
    "# idx = pd.PeriodIndex(periods)\n",
    "# sales_df=sales_df.set_index(idx).drop([\"DATE_ORDER\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "as we mentioned on the **EXPLORATORY DATA ANALYSIS**, we will remove some bad data from our dataset to avoid propagating these errors to the model (using helper functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sales_df = cleaning_funcs.clean_sales_dataframe(sales_df);sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we group by the product ID and the date the price was sampled.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_1 = sales_df.groupby([sales_df.PROD_ID,sales_df.DATE_ORDER],as_index=False).agg({\n",
    "    \"QTY_ORDER\":np.sum,\n",
    "    \"REVENUE\": np.sum,\n",
    "    \"UNIT_PRICE\": np.mean\n",
    "})\n",
    "grouped_1.sample(10)\n",
    "\n",
    "\n",
    "# len(sales_df[sales_df.DATE_ORDER < '2015-10-14 00:00:00'])\n",
    "# len(sales_df[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> note that the first approach treats each product individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g1 = sales_df.groupby([sales_df.PROD_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g1 = sales_df.groupby([sales_df.PROD_ID])\n",
    "(p1,p2,p3,p4,p5,p6,p7,p8,p9) = [g1.get_group(prod_id) for prod_id in g1.groups.keys()]\n",
    "\n",
    "dataset7 = p7.groupby(p7.DATE_ORDER).agg({\n",
    "    \"QTY_ORDER\":np.sum,\n",
    "    \"UNIT_PRICE\": np.mean\n",
    "})\n",
    "dataset7.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## now that we have selected data only for P7, let's train a simple model on it\n",
    "\n",
    "> remember, we'll use UNIT_PRICE and QTY_ORDER for the N=3 previous days to try to model what the next (4th) day. \n",
    "\n",
    "Note that we have **aggregated**, i.e. combined all rows for a given day (in the original dataset, there were multiple entries for the same product *and* the same day so we aggregated those)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset7.sort_index(inplace=True)\n",
    "dataset7.reset_index(inplace=True)\n",
    "dataset7[dataset7.DATE_ORDER.dt.month==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for row in dataset7.values:\n",
    "    print(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dataset as dataset_funcs\n",
    "\n",
    "dataset7[dataset7.iloc[:,0] == pd.tslib.Timestamp('2015-06-30 00:00:00')].index.tolist()[0]\n",
    "\n",
    "# type(dataset7.iloc[0])\n",
    "# type(dataset7.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lst = [[2,3,4],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2, 3, 4], [4, 5, 6]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = []\n",
    "lst1.append(lst)\n",
    "lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 // 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
